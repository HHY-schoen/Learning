{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 把 TaggerCore 目錄添加到 sys.path\n",
    "sys.path.append(os.path.join(os.getcwd(), 'TaggerCore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python38.zip',\n",
       " '/usr/lib/python3.8',\n",
       " '/usr/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/schoenhsiung/.virtualenvs/py38/lib/python3.8/site-packages',\n",
       " '/home/schoenhsiung/crawler/Z_download/product_tagger/TaggerCore']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from data.test_data import grp_data, etk_data\n",
    "from TaggerCore.tagger import ProductTagger\n",
    "import requests\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['首爾旅遊｜賞楓內藏山.雞籠山國立公園.華蓋庭園.江華島傳燈寺.青瓦臺.全州韓屋村.明洞(二站購物)六日',\n",
       " '洄來花蓮玩｜五星西班牙美學理想大地、歐風水岸星巴克、飄飄雲朵、羅山瀑布、小吃美食二日｜台南高雄出發',\n",
       " '追楓東北|超人氣景點~只見線橋梁美景.藏王纜車.五色沼遊湖.塔之崖.秋保瀑布.會津若松城.仙台牛舌餐.溫泉五日',\n",
       " '魅力歐洲｜德瑞法｜海德古堡纜車、萊茵河三遊船、凱旋門登頂趣、全覽鐵力士山10日',\n",
       " '花蓮旅遊｜11/02、11/03限定｜洄瀾漾起來.東大門【一路向東】演唱會.出遊挺花蓮二日｜台中出發',\n",
       " '東京清倉特惠｜富士山美景.忍野八海.麻布台之丘.豐洲千客萬來五日']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo partial data from .xlxs file\n",
    "title = grp_data['title']\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tag definition\n",
    "with open('./data/activity_tag.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_tag_product(model_name, model_api_base, format_args):\n",
    "    \"\"\"\n",
    "    Create a ProductTagger, format the messages, and tag the product synchronously.\n",
    "    \"\"\"\n",
    "    tagger = ProductTagger(model_name, model_api_base)\n",
    "    tagger.format_messages(format_args)\n",
    "    result = tagger.Tag()  # Synchronous call to Tag()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tokenizer...\n",
      "Tokenizer Loaded.\n",
      "Messages Formatted.\n"
     ]
    }
   ],
   "source": [
    "## def create_and_tag_product() 步驟拆解\n",
    "from TaggerCore import prompts\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# tagger basic saetting\n",
    "SYS_PROMPT = prompts.SYS_PROMPT\n",
    "USER_PROMPT = prompts.USER_PROMPT\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "print('Loading Tokenizer...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print('Tokenizer Loaded.')\n",
    "model_api_base = \"http://10.34.6.6:8000/generate\"\n",
    "\n",
    "messages = []\n",
    "\n",
    "# format massage\n",
    "format_args_2 = {\n",
    "    'tag_definition': data['放鬆'],\n",
    "    'product_info': title[4]\n",
    "}\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": USER_PROMPT.format(**format_args_2)}\n",
    "]\n",
    "__cache_messages = [\n",
    "    {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": USER_PROMPT.format(**format_args_2)}\n",
    "]\n",
    "print('Messages Formatted.')\n",
    "\n",
    "# tag\n",
    "prompt = tokenizer.apply_chat_template(    # tokenizer.apply_chat_template(): 主要用來格式化對話（Chat）類型的輸入，使其適合用於模型推理（Inference）。\n",
    "    messages,\n",
    "    tokenize=False,    # False: 返回格式化後的純文字字串（適合人工檢查）、True: 返回的是 Token ID（適合模型推理）\n",
    "    add_generation_prompt=True    # 是否自動添加生成提示。True: 會自動在對話結尾加上模型應該繼續生成的提示，適合用於聊天機器人的輸入，確保模型知道它應該產生下一個回應。\n",
    ")\n",
    "\n",
    "# output = self.chatbot.chat(prompt)  # Asynchronous chat\n",
    "params = {\n",
    "    \"max_new_tokens\": 2000,  # 生成的最大 Token 數量\n",
    "    \"temperature\": 0.5,  # 溫度，決定隨機性\n",
    "    \"top_p\": 0.5,  # 核採樣\n",
    "    \"top_k\": 85,  # 取前 K 個最高機率的 Token\n",
    "    \"repetition_penalty\": 1.0,  # 重複懲罰，防止模型重複內容\n",
    "    \"do_sample\": True,  # 啟用隨機取樣\n",
    "}\n",
    "# model_api_base = <your api url>\n",
    "resp = requests.post(model_api_base, json=params)  # request model\n",
    "text = resp.json()[\"text\"][0]  # get return text\n",
    "# parse output response\n",
    "response = text[text.rfind('<|im_start|>assistant\\n') + 22:]\n",
    "response_json = ast.literal_eval(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
